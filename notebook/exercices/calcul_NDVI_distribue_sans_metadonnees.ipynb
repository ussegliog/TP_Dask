{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de cas d'utilisation de Dask avec un TIF\n",
    "\n",
    "Dans ce notebook, nous cherchons à utiliser Dask et ses modules sur des TIF afin de faire du calcul distribué.\n",
    "\n",
    "Nous proposons ici un exemple simple : calcul de NDVI sur ces TIF.\n",
    "\n",
    "Les API utilisées sont également simples, pas d'affichage cartographique ici, on utilise seulement les dask.array, un équivelent des numpy.array en version distribuée. Nous chargerons donc les TIF sous forme de tableaux multidimensionnels et réaliserons le calcul de NDVI.\n",
    "\n",
    "\n",
    "## Initialisation du client et du cluster\n",
    "\n",
    "Nous pouvons utiliser le cluster TREX en créant 2 workers avec 2 cpus et 16GB de RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "account_TREX ='formation_isae'\n",
    "partition_Trex = \"cpu19_rh8\"\n",
    "qos_Trex = \"--qos=cpu_2019_40\"\n",
    "\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    # Dask-worker specific keywords\n",
    "    n_workers=2,                # start 2 workers\n",
    "    cores=2,                    # each worker runs on 2 cores\n",
    "    memory=\"8GB\",              # each worker uses 8GB memory (on TREX g2022 : nb_cores*8Go, on g2019 : nb_cores*4.6Go )\n",
    "    processes=1,                # Number of Python processes to cut up each job\n",
    "    local_directory='$TMPDIR',  # Location to put temporary data if necessary\n",
    "    account=account_TREX,\n",
    "    queue = partition_Trex,\n",
    "    walltime='01:00:00',\n",
    "    interface='ib0',\n",
    "    log_directory='../dask-logs',\n",
    "    job_extra_directives=[qos_Trex] # qos to use\n",
    ")\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation des modules\n",
    "\n",
    "On récupère les modules nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.array.image import imread\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des fonctions utilisées\n",
    "\n",
    "La fonction realizeNDVI va réaliser le calcul de NDVI (différence normalisée) sur le TIF, c'est une simple opération de type tableau numpy, réalisable avec des tableaux dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def realizeNDVI(inputImage):\n",
    "    return (inputImage[:, :, :, 2] - inputImage[:, :, :, 3]) / (inputImage[:, :, :, 3] + inputImage[:, :, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des TIF\n",
    "\n",
    "Nous récupérons les TIFs suivant pour ce notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.5G\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 565M May 13  2020 SPOT5_HRG2_XS_20150411_N1_TUILE_ArlesFranceD0000B0000.TIF\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 565M May 13  2020 SPOT5_HRG2_XS_20150511_N1_TUILE_ArlesFranceD0000B0000.TIF\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 565M May 13  2020 SPOT5_HRG2_XS_20150605_N1_TUILE_ArlesFranceD0000B0000.TIF\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 565M May 13  2020 SPOT5_HRG2_XS_20150720_N1_TUILE_ArlesFranceD0000B0000.TIF\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 565M May 13  2020 SPOT5_HRG2_XS_20150725_N1_TUILE_ArlesFranceD0000B0000.TIF\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 565M May 13  2020 SPOT5_HRG2_XS_20150809_N1_TUILE_ArlesFranceD0000B0000.TIF\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 565M May 13  2020 SPOT5_HRG2_XS_20150819_N1_TUILE_ArlesFranceD0000B0000.TIF\n",
      "-rwxrwxr-x+ 1 geninv cneshpc 563M May 13  2020 SPOT5_HRG2_XS_20150903_N1_TUILE_ArlesFranceD0000B0000.TIF\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /work/datalake/pangeo_demo/rt_algos/N1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation du Dask.array contenant les TIF\n",
    "\n",
    "L'API dask array propose une méthode pour lire un ensemble de fichier TIF.\n",
    "Afin de simuler un plus grand nombre de fichier, nous allons concaténer plusieurs fois le même array en mémoire. Utilisation de la fonction `imread`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code \n",
    "# images_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_array = imread('/work/datalake/pangeo_demo/rt_algos/N1/*')\n",
    "images_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginons donc que nous avons plus de 8 images en duplicant les tableaux (multiplication \"articielle\" du nb images) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "big_images_array = da.concatenate([images_array] * 10)\n",
    "big_images_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de retuiler les images si le calcul est complexe et à besoin de chunks plus petit.\n",
    "Dans le cas présent on va limiter, car ce n'est pas vraiment la peine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "big_images_array = big_images_array.rechunk((1, 4050, 4550, 4))\n",
    "big_images_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du NDVI et affichage\n",
    "\n",
    "On réalise le calcul de NDVI sur les différentes images de manière distribuée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndviTIF = realizeNDVI(big_images_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer et afficher le résultat sur trois images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "april = ndviTIF[0].compute()\n",
    "june = ndviTIF[2].compute()\n",
    "august = ndviTIF[6].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(figsize=(13, 3), ncols=3)\n",
    "ax1.set_title('2015/04/11')\n",
    "ax2.set_title('2015/06/05')\n",
    "ax3.set_title('2015/08/19')\n",
    "\n",
    "pos = ax1.imshow(april)\n",
    "pos1 = ax2.imshow(june)\n",
    "pos2 = ax3.imshow(august)\n",
    "fig.colorbar(pos, ax=ax3, label=\"NVDI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi calculer la moyenne du NDVI sur chaque image, attention à ignorer les nan à cause de potentielles division par zero.\n",
    "\n",
    "Forcément le résultat sera cyclique vu qu'on répète toujours les 8 mêmes images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "times = 2\n",
    "nb_tiff = times * 8\n",
    "\n",
    "meanNdviTIF = da.nanmean(ndviTIF[0:nb_tiff], axis=(1,2))\n",
    "\n",
    "plt.plot(meanNdviTIF.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pangeo Stable",
   "language": "python",
   "name": "pangeo_stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
